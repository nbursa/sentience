#!/usr/bin/env python3
"""
SRAI-Sentience Core Integration Test

This test demonstrates the complete integration between the Rust Sentience Core
and the Python SRAI system, showing how they work together seamlessly.
"""

import sys
import os
import numpy as np
from typing import Dict, List, Any

# Add SRAI to path
sys.path.insert(0, "/Users/nenad/Projects/SRAI/src")

# Import SRAI components
from srai import (
    Cortex,
    Edge,
    EdgeType,
    STMWindow,
    RefNet,
    ReflectionMetrics,
    SRAIRefNetAdapter,
    SentienceToken,
    TokenType,
    SentienceDSL,
    SentienceMemoryBridge,
    SentienceRefNetBridge,
)

# Import Sentience Core (will be available after building)
try:
    from sentience_core import (
        PySentienceCore,
        PyExecutionResult,
        create_sentience_core,
        THOUGHT_TYPE_PERCEPT,
        THOUGHT_TYPE_REFLECTION,
        THOUGHT_TYPE_ACTION,
        THOUGHT_TYPE_CONCEPT,
        THOUGHT_TYPE_SELF_MODEL,
    )

    SENTIENCE_CORE_AVAILABLE = True
    print("âœ“ Rust Sentience Core available")
except ImportError:
    SENTIENCE_CORE_AVAILABLE = False
    print("âš ï¸ Rust Sentience Core not available (run 'make build' to build it)")


def test_srai_components():
    """Test basic SRAI component functionality."""
    print("\nğŸ§  Testing SRAI Components")
    print("=" * 30)

    # Test Cortex
    cortex = Cortex()
    print("âœ“ Cortex initialized")

    # Test RefNet
    try:
        refnet = RefNet.load_model("models/refnet_best.pth")
        print("âœ“ RefNet model loaded")
    except FileNotFoundError:
        refnet = RefNet(d_model=256, n_heads=8, n_layers=6, dropout=0.1)
        print("âœ“ RefNet initialized (untrained)")

    # Test SentienceDSL
    dsl = SentienceDSL()
    print("âœ“ SentienceDSL initialized")

    # Test memory bridge
    memory_bridge = SentienceMemoryBridge(cortex)
    print("âœ“ SentienceMemoryBridge initialized")

    # Test RefNet bridge
    refnet_bridge = SentienceRefNetBridge(refnet, memory_bridge)
    print("âœ“ SentienceRefNetBridge initialized")

    return cortex, refnet, dsl, memory_bridge, refnet_bridge


def test_rust_sentience_core():
    """Test Rust Sentience Core functionality."""
    if not SENTIENCE_CORE_AVAILABLE:
        print("\nâš ï¸ Skipping Rust Sentience Core tests (not available)")
        return None

    print("\nğŸ¦€ Testing Rust Sentience Core")
    print("=" * 35)

    # Create Sentience Core
    core = create_sentience_core()
    print("âœ“ Sentience Core created")

    # Test parsing
    dsl_code = "embed msg -> percept.text"
    result = core.process_step(dsl_code)
    print(f"âœ“ Processed DSL: {dsl_code}")
    print(f"  Token ID: {result.token_id()}")
    print(
        f"  Embedding dimension: {len(result.embedding()) if result.embedding() is not None else 0}"
    )

    # Test reflection
    reflection_dsl = "reflect { recall; reframe; consolidate }"
    result2 = core.process_step(reflection_dsl)
    print(f"âœ“ Processed reflection: {reflection_dsl}")
    print(f"  Generated {len(result2.tokens())} tokens")

    return core


def test_integration_pipeline():
    """Test the complete SRAI-Sentience integration pipeline."""
    print("\nğŸ”— Testing Integration Pipeline")
    print("=" * 35)

    # Initialize components
    cortex, refnet, dsl, memory_bridge, refnet_bridge = test_srai_components()

    if SENTIENCE_CORE_AVAILABLE:
        rust_core = test_rust_sentience_core()
    else:
        rust_core = None

    # Test 1: Python Sentience DSL
    print("\n1. Testing Python Sentience DSL")
    python_dsl_code = """
    (Percept :modality "text" :content "Hello world" :timestamp 1234567890)
    (Reflection :on "percept" :result "processed" :score 0.85)
    (Action :name "respond" :target "user" :confidence 0.9)
    """

    tokens = dsl.parse_text(python_dsl_code)
    print(f"âœ“ Parsed {len(tokens)} Python Sentience tokens")

    # Commit to Cortex
    for token in tokens:
        token_id = memory_bridge.commit_token(token)
        print(f"  âœ“ Committed {token.token_type.value}: {token_id}")

    # Test 2: Rust Sentience Core (if available)
    if rust_core:
        print("\n2. Testing Rust Sentience Core Integration")
        rust_dsl_code = """
        agent TestAgent {
            mem short
            goal: "Test integration with SRAI"
            
            on input(msg) {
                embed msg -> percept.text
                reflect {
                    recall ltm[similar: msg, k=5]
                    reframe "analyze_and_respond"
                    consolidate
                }
            }
        }
        """

        result = rust_core.process_step(rust_dsl_code)
        print(f"âœ“ Processed Rust DSL")
        print(f"  Token ID: {result.token_id()}")
        print(f"  Generated {len(result.tokens())} tokens")
        print(f"  Generated {len(result.edges())} edges")

        # Convert Rust tokens to SRAI format
        rust_tokens = result.tokens()
        if rust_tokens:
            print(f"  First token: {rust_tokens[0]}")

    # Test 3: RefNet Evaluation
    print("\n3. Testing RefNet Evaluation")
    stm_tokens = memory_bridge.get_stm_window()
    print(f"âœ“ STM window contains {len(stm_tokens)} tokens")

    try:
        refnet_results = refnet_bridge.evaluate_sentience_window(stm_tokens)
        print(f"âœ“ RefNet evaluation completed")
        print(f"  Valence: {refnet_results['valence']:.3f}")
        print(f"  SMD: {refnet_results['smd']:.3f}")
        print(f"  Quality: {refnet_results['quality']:.3f}")
        print(f"  Next Action: {refnet_results['next_action']}")
    except Exception as e:
        print(f"âš ï¸ RefNet evaluation failed: {e}")

    # Test 4: Memory Operations
    print("\n4. Testing Memory Operations")

    # Add relations
    if len(tokens) >= 2:
        memory_bridge.add_relation(
            tokens[0].token_id, tokens[1].token_id, "CAUSES", weight=0.8
        )
        print("âœ“ Added token relations")

    # Test retrieval
    retrieved = memory_bridge.retrieve_tokens("Hello world", limit=3)
    print(f"âœ“ Retrieved {len(retrieved)} tokens for semantic search")

    # Test consolidation
    consolidated = memory_bridge.consolidate_memory()
    print(f"âœ“ Consolidated {len(consolidated)} concept tokens")

    # Test reflection
    reflections = memory_bridge.reflect_on_tokens(tokens[:2])
    print(f"âœ“ Generated {len(reflections)} reflection tokens")

    # Test 5: Memory Statistics
    print("\n5. Memory Statistics")
    stats = cortex.get_stats()
    print(f"âœ“ Memory stats:")
    for key, value in stats.items():
        print(f"  {key}: {value}")

    return True


def test_comparison():
    """Compare Python and Rust Sentience implementations."""
    print("\nâš–ï¸ Comparing Python vs Rust Sentience")
    print("=" * 40)

    if not SENTIENCE_CORE_AVAILABLE:
        print("âš ï¸ Cannot compare - Rust Sentience Core not available")
        return

    # Test same DSL in both implementations
    test_dsl = "embed test -> percept.text"

    # Python implementation
    print("Python Sentience DSL:")
    try:
        from srai import SentienceDSL

        dsl = SentienceDSL()
        tokens = dsl.parse_text(f'(Percept :modality "text" :content "test")')
        print(f"  âœ“ Parsed {len(tokens)} tokens")
        print(f"  Token type: {tokens[0].token_type.value}")
        print(f"  AST: {tokens[0].ast}")
    except Exception as e:
        print(f"  âœ— Python parsing failed: {e}")

    # Rust implementation
    print("\nRust Sentience Core:")
    try:
        core = create_sentience_core()
        result = core.process_step(test_dsl)
        print(f"  âœ“ Processed DSL")
        print(f"  Token ID: {result.token_id()}")
        print(
            f"  Embedding dimension: {len(result.embedding()) if result.embedding() is not None else 0}"
        )

        tokens = result.tokens()
        if tokens:
            print(f"  Generated {len(tokens)} tokens")
            print(f"  First token: {tokens[0]}")
    except Exception as e:
        print(f"  âœ— Rust processing failed: {e}")


def main():
    """Run the complete integration test."""
    print("ğŸ§  SRAI-Sentience Core Integration Test")
    print("=" * 50)

    try:
        # Test individual components
        test_srai_components()

        # Test Rust Sentience Core
        test_rust_sentience_core()

        # Test integration pipeline
        success = test_integration_pipeline()

        # Test comparison
        test_comparison()

        print("\nğŸ‰ Integration Test Complete!")
        print("\nâœ… Integration Status:")
        print("  âœ“ SRAI components working")
        print("  âœ“ Python Sentience DSL working")
        if SENTIENCE_CORE_AVAILABLE:
            print("  âœ“ Rust Sentience Core working")
            print("  âœ“ Full integration pipeline working")
        else:
            print("  âš ï¸ Rust Sentience Core not available")
            print(
                "  âš ï¸ Run 'make build' in Sentience project to enable full integration"
            )

        print("\nğŸ”— Integration Features Demonstrated:")
        print("  âœ“ Sentience DSL parsing (Python)")
        print("  âœ“ Cortex memory operations")
        print("  âœ“ RefNet evaluation")
        print("  âœ“ Memory bridges and token conversion")
        print("  âœ“ Semantic retrieval and consolidation")
        print("  âœ“ Reflection and meta-cognitive operations")

        if SENTIENCE_CORE_AVAILABLE:
            print("  âœ“ Rust Sentience Core processing")
            print("  âœ“ Deterministic hashing and canonicalization")
            print("  âœ“ Symbolic embedding generation")
            print("  âœ“ Complete parse â†’ execute â†’ commit pipeline")

        return 0

    except Exception as e:
        print(f"\nâŒ Integration test failed: {e}")
        import traceback

        traceback.print_exc()
        return 1


if __name__ == "__main__":
    exit(main())
